# -*- coding: utf-8 -*-
"""CHATBOT_FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tDT-Pk3LeUJ8M-jJMpT9QyBEJvKP4i6y
"""

!pip install langchain
!pip install openai
!pip install PyPDF2
!pip install faiss-cpu
!pip install tiktoken

from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS

# Get your API keys from openai, you will need to create an account.
# Here is the link to get the keys: https://platform.openai.com/account/billing/overview
import os
from google.colab import userdata
os.environ["OPENAI_API_KEY"] = "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"

os.environ["OPENAI_API_KEY"] = "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"

import requests
from PyPDF2 import PdfReader

pdf_url = 'https://www.cs.cmu.edu/~fgandon/documents/lecture/uk1999/operating_system/operating_system.pdf'

# Fetch the PDF content from the URL
response = requests.get(pdf_url)

# Save the PDF content to a file
with open('downloaded_pdf.pdf', 'wb') as file:
    file.write(response.content)

# Read the PDF file
with open('downloaded_pdf.pdf', 'rb') as file:
    pdf_reader = PdfReader(file)
    # Now you can use the pdf_reader object as needed
    # For example, to get the number of pages:
    num_pages = len(pdf_reader.pages)
    print(f"Number of pages: {num_pages}")

with open('downloaded_pdf.pdf', 'rb') as file:
    pdf_reader = PdfReader(file)

    # Initialize raw_text variable
    raw_text = ''

    # Iterate through pages and extract text
    for i, page in enumerate(pdf_reader.pages):
        text = page.extract_text()
        if text:
            raw_text += text

# raw_text

raw_text[:100]

# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits.

text_splitter = CharacterTextSplitter(
    separator = "\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)
texts = text_splitter.split_text(raw_text)

len(texts)

texts[0]

texts[1]

# Download embeddings from OpenAI
embeddings = OpenAIEmbeddings()

docsearch = FAISS.from_texts(texts, embeddings)

docsearch

from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI

chain = load_qa_chain(OpenAI(), chain_type="stuff")

query = "pretend you are an expert in OS. Engage in a conversation with me about operating systems and its working."
# Continue the conversation until the user says "exit"
while True:
    # Get user input
    user_input = input("User: ")

    # Check if the user wants to exit
    if user_input.lower() == "exit":
        print("Chatbot: Goodbye! Exiting the chat.")
        break

    # Perform similarity search and generate a response
    docs = docsearch.similarity_search(user_input)
    response = chain.run(input_documents=docs, question=user_input)

    # Display the chatbot's response
    print("Chatbot:", response)

!pip install gradio

# Define function for Gradio interface
import gradio as gr
def chatbot_interface(Enter_Query):
    # Check if the user wants to exit
    if Enter_Query.lower() == "exit":
        return "Chatbot: Goodbye! Exiting the chat."

    # Perform similarity search and generate a response
    docs = docsearch.similarity_search(user_input)
    response = chain.run(input_documents=docs, question=Enter_Query)

    # Return the chatbot's response
    return "Chatbot: " + response

# Create Gradio interface with title
iface = gr.Interface(fn=chatbot_interface, inputs=["text"], outputs="text", live=True, title="Chatbot Interface")

# Launch the interface
iface.launch()